== [[DeltaDataSource]] DeltaDataSource -- Entry Point of Delta Data Source

`DeltaDataSource` is a <<DataSourceRegister, DataSourceRegister>> and acts as the entry point to all features provided by `delta` data source.

`DeltaDataSource` is a <<RelationProvider, RelationProvider>>.

`DeltaDataSource` is a <<StreamSinkProvider, StreamSinkProvider>> for a streaming sink for streaming queries (Structured Streaming).

=== [[delta-format]][[DataSourceRegister]] DataSourceRegister for delta alias

`DeltaDataSource` is a `DataSourceRegister` and registers itself to be available using `delta` alias.

.Reading From Delta Table
[source, scala]
----
assert(spark.isInstanceOf[org.apache.spark.sql.SparkSession])
spark.read.format("delta")
spark.readStream.format("delta")
----

.Writing To Delta Table
[source, scala]
----
assert(df.isInstanceOf[org.apache.spark.sql.Dataset[_]])
df.write.format("delta")
df.writeStream.format("delta")
----

TIP: Read up on https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-DataSourceRegister.html[DataSourceRegister] in https://bit.ly/spark-sql-internals[The Internals of Spark SQL] online book.

`DeltaDataSource` is registered using `META-INF/services/org.apache.spark.sql.sources.DataSourceRegister`:

[source, scala]
----
org.apache.spark.sql.delta.sources.DeltaDataSource
----

=== [[RelationProvider]][[RelationProvider-createRelation]] RelationProvider

`DeltaDataSource` is a `RelationProvider`.

TIP: Read up on https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-RelationProvider.html[RelationProvider] in https://bit.ly/spark-sql-internals[The Internals of Spark SQL] online book.

[source, scala]
----
createRelation(
  sqlContext: SQLContext,
  parameters: Map[String, String]): BaseRelation
----

`createRelation`...FIXME

In the end, `createRelation` requests the <<RelationProvider-createRelation-deltaLog, DeltaLog>> to <<DeltaLog.adoc#createRelation, createRelation>>

=== [[CreatableRelationProvider]][[CreatableRelationProvider-createRelation]] CreatableRelationProvider

`DeltaDataSource` is a `CreatableRelationProvider`.

TIP: Read up on https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-CreatableRelationProvider.html[CreatableRelationProvider] in https://bit.ly/spark-sql-internals[The Internals of Spark SQL] online book.

=== [[StreamSourceProvider]][[createSource]] Creating Streaming Source (Structured Streaming) -- `createSource` Method

`DeltaDataSource` is a `StreamSourceProvider`.

TIP: Read up on https://jaceklaskowski.gitbooks.io/spark-structured-streaming/spark-sql-streaming-StreamSourceProvider.html[StreamSourceProvider] in https://bit.ly/spark-structured-streaming[The Internals of Spark Structured Streaming] online book.

=== [[StreamSinkProvider]][[createSink]] Creating Streaming Sink (Structured Streaming) -- `createSink` Method

`DeltaDataSource` is a `StreamSinkProvider` for a streaming sink for Structured Streaming.

TIP: Read up on https://jaceklaskowski.gitbooks.io/spark-structured-streaming/spark-sql-streaming-StreamSinkProvider.html[StreamSinkProvider] in https://bit.ly/spark-structured-streaming[The Internals of Spark Structured Streaming] online book.

`DeltaDataSource` supports `Append` and `Complete` output modes only.

In the end, `DeltaDataSource` creates a <<DeltaSink.adoc#, DeltaSink>>.

TIP: Consult the demo <<demo-Using-Delta-Lake-as-Streaming-Sink-in-Structured-Streaming.adoc#, Using Delta Lake (as Streaming Sink) in Streaming Queries>>.

== [[getTimeTravelVersion]] `getTimeTravelVersion` Internal Method

[source, scala]
----
getTimeTravelVersion(
  parameters: Map[String, String]): Option[DeltaTimeTravelSpec]
----

`getTimeTravelVersion`...FIXME

NOTE: `getTimeTravelVersion` is used exclusively when `DeltaDataSource` is requested to <<RelationProvider-createRelation, create a relation (as a RelationProvider)>>.
